{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing the News Headlines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geonamescache\n",
    "from collections import Counter\n",
    "import unidecode\n",
    "import re\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the text file and make a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines = pd.read_csv('discovering-disease-outbreaks-base/data/headlines.txt',\n",
    "                        header=None, \n",
    "                        delimiter='\\n',\n",
    "                        names=['Headlines'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Headlines</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>Duluth Patient in Critical Condition after Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>How to Avoid Pneumonia in Bullhead City</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>More people in Cranford are infected with Hepa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>Framingham Residents Receive Measles vaccine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Ebola outbreak in Kampala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Headlines\n",
       "566  Duluth Patient in Critical Condition after Con...\n",
       "300            How to Avoid Pneumonia in Bullhead City\n",
       "541  More people in Cranford are infected with Hepa...\n",
       "335       Framingham Residents Receive Measles vaccine\n",
       "91                           Ebola outbreak in Kampala"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headlines.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of headlines: 650\n",
      "Max lenght of headlines: 87\n",
      "Min lenght of headlines: 16\n",
      "Average lenght of headlines: 40.77\n"
     ]
    }
   ],
   "source": [
    "# Check some informations about headlines\n",
    "print(\"Number of headlines: {}\".format(headlines.shape[0]))\n",
    "print(\"Max lenght of headlines: {}\".format(max([len(each[0]) for each in headlines.values])))\n",
    "print(\"Min lenght of headlines: {}\".format(min([len(each[0]) for each in headlines.values])))\n",
    "print(\"Average lenght of headlines: {:.2f}\".format(np.mean([len(each[0]) for each in headlines.values])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Countries and Cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init geonamecashe instance\n",
    "gc = geonamescache.GeonamesCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the name of all the cities into a list\n",
    "cities = [city['name'] for city in gc.get_cities().values()]\n",
    "# Extract all the country names into a list\n",
    "countries = [country['name'] for country in gc.get_countries().values()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of cities: 24336\n",
      "Total number of countries: 252\n"
     ]
    }
   ],
   "source": [
    "print(\"Total number of cities: {}\".format(len(cities)))\n",
    "print(\"Total number of countries: {}\".format(len(countries)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Springfield', 8),\n",
       " ('San Pedro', 7),\n",
       " ('Richmond', 7),\n",
       " ('San Fernando', 7),\n",
       " ('Mercedes', 6),\n",
       " ('La Paz', 6),\n",
       " ('Victoria', 6),\n",
       " ('San Francisco', 6),\n",
       " ('Auburn', 6),\n",
       " ('Santa Cruz', 6)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find duplicate\n",
    "city_counter = Counter(cities)\n",
    "city_counter.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove accent marks\n",
    "country_accent_mapping = {\n",
    "    unidecode.unidecode(country): country for country in countries}\n",
    "\n",
    "city_accent_mapping = {\n",
    "    unidecode.unidecode(city): city for city in cities\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the dataframe from accent marks\n",
    "headlines_clean = pd.DataFrame(\n",
    "    {\n",
    "        \"Headlines\":[unidecode.unidecode(headline[0]) for headline in headlines.values]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save cleaned cities and countries into a list\n",
    "clean_cities = list(city_accent_mapping.keys())\n",
    "clean_countries = set(country_accent_mapping.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the city and country names\n",
    "clean_cities = sorted(clean_cities, key=lambda x: len(x), reverse=True)\n",
    "clean_countries = sorted(clean_countries, key=lambda x:len(x), reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Match countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "city_regex = r'\\b|\\b'.join(clean_cities)\n",
    "country_regex = r'\\b|\\b'.join(clean_countries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_country_and_city(headline):\n",
    "    city = re.search(city_regex, headline)\n",
    "    country = re.search(country_regex, headline)\n",
    "    cities = None if not city else city.group(0)\n",
    "    countries = None if not country else country.group(0)\n",
    "    return dict(headline=headline, countries=countries, cities=cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines_extracted_cities_countries = [\n",
    "    find_country_and_city(headline[0]) for headline in headlines.values\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = pd.DataFrame(headlines_extracted_cities_countries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save files for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file = \"headlines_with_city_country.json\"\n",
    "with open(save_file, 'w') as f:\n",
    "    f.write(json.dumps(headlines_extracted_cities_countries))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"city_accent_mapping.json\", 'w') as f:\n",
    "    f.write(json.dumps(city_accent_mapping))\n",
    "    \n",
    "with open(\"country_accent_mapping.json\", 'w') as f:\n",
    "    f.write(json.dumps(country_accent_mapping))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
